{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_image_size = tuple((256, 256))\n",
    "\n",
    "\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            image = cv2.resize(image, default_image_size)   \n",
    "            return img_to_array(image)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list_a, label_list = [], []\n",
    "\n",
    "totalImage = 0\n",
    "\n",
    "root_dir = listdir(\"PlantVillage/\")\n",
    "\n",
    "for image_folder in root_dir :\n",
    "    image_list = listdir(f\"PlantVillage/{image_folder}\")\n",
    "    \n",
    "    for image in image_list:\n",
    "        image_name = f\"PlantVillage/{image_folder}/\"+image\n",
    "        if isinstance(image_name, str) == True:\n",
    "            if image_name.endswith(\".jpg\") == True or image_name.endswith(\".JPG\") == True:\n",
    "                image_list_a.append(convert_image_to_array(image_name))\n",
    "                label_list.append(image_folder)\n",
    "        totalImage = totalImage+1\n",
    "        if(totalImage>=10):\n",
    "            \n",
    "            break\n",
    "print(len(label_list),len(np.unique(np.asarray(label_list))))\n",
    "from sys import getsizeof\n",
    "getsizeof(image_list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_a = np.asarray(image_list_a)\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_list_a, image_labels, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 4)       112       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 256, 4)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 85, 85, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 85, 85, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28900)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 524)               15144124  \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 524)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 524)               2096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 524)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                7875      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 15,155,231\n",
      "Trainable params: 15,153,671\n",
      "Non-trainable params: 1,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "width=256\n",
    "height=256\n",
    "depth=3\n",
    "inputShape = (height, width, depth)\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3]) \n",
    "chanDim = 1\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(4, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(524))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 19 samples, validate on 5 samples\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 5s 280ms/step - loss: 0.3386 - acc: 0.9158 - val_loss: 1.4025 - val_acc: 0.8667\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 2s 119ms/step - loss: 0.2251 - acc: 0.9228 - val_loss: 0.5949 - val_acc: 0.8933\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 0.2479 - acc: 0.9368 - val_loss: 0.6475 - val_acc: 0.8933\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 2s 121ms/step - loss: 0.2031 - acc: 0.9439 - val_loss: 0.5597 - val_acc: 0.8667\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 2s 117ms/step - loss: 0.1865 - acc: 0.9404 - val_loss: 0.4752 - val_acc: 0.8800\n"
     ]
    }
   ],
   "source": [
    "'''history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size=BS),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // BS,\n",
    "    epochs=EPOCHS, verbose=1\n",
    "    )\n",
    "'''\n",
    "history = model.fit(x_train, y_train, batch_size=2,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=EPOCHS, verbose=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
